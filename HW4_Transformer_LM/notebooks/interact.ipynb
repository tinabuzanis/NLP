{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate text with your tranied lagnuage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from transformer_lm.modeling_transformer import TransformerLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see error `404 Client Error: Not Found` it probably means that \"../output\" is not the correct directory with your tokenizer and model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"../cli/outdir\")\n",
    "model = TransformerLM.from_pretrained(\"../cli/outdir\")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use method `.generate()` to continue your text. This is how it works:\n",
    "\n",
    "1. It accepts a batch of input_ids (batch can contain consist of a single example, but should have the shape [1, sequence_length]).\n",
    "1. The model generates a probability distribution over your vocabulary and selects the token_id with the highest probability.\n",
    "1. This token_id is added to the input_ids and the process repeats untill you reach sequence size = max_length\n",
    "\n",
    "This is a very crude and simple way of generating text. You may notice that the model tends to repeat the same word after a certain point (however, if produces the same word all the time, it is probably not trained perfectly). We will learn more ways of how to generate text given the distribution of the next token later in class.\n",
    "\n",
    "You can find the implementation of `.generate()` in `transformer_lm/modeling_transformer.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'meaning of life is global ̧ conscious turn lies conscious Allen blue и conscious elev Allen Gar the conscious す story explained plus Ter global explained plus ancy conscious battleships す plus ancy ̧'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please keep this example as it is.\n",
    "input_ids = tokenizer(\"The meaning of life is\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "generated_ids = model.generate(input_ids, max_length=30)\n",
    "generated_text = tokenizer.decode(generated_ids[0])\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try to generate more text.\n",
    "### Play with different prefixes and max_length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i learned that и и Allen conscious turn す conscious Allen plus Allen conscious explained plus す conscious battleships す story и и conscious す the plus cles conscious touchdown plus Allen conscious battleships Allen released the ρ plus Inter Allen released turn oncé и cess и conscious the determin す the global'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = tokenizer(\"today i learned that\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "generated_ids = model.generate(input_ids, max_length=50)\n",
    "generated_text = tokenizer.decode(generated_ids[0])\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f86d5ac646110a331c60478f9400a1a64d0cd523be90d887457228f9723636b5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
